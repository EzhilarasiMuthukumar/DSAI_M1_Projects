\documentclass[runningheads]{llncs}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}

\begin{document}

\title{AI for Software Vulnerability Management: Detection, Prioritization, and Remediation}

\author{Conference Summary}

\institute{SophI.A Summit 2025, November 19--21, Sophia Antipolis}

\maketitle

\begin{abstract}
Merve Sahin from SAP Product Security presented research on using Large Language Models for software vulnerability management, covering detection, prioritization, and remediation. The results show strong promise for LLMs in automated repair, but also highlight persistent challenges in detection and reasoning that require human intervention. The most practical paths for future combine LLMs with traditional security tools within agentic frameworks.
\end{abstract}

\keywords{Software Vulnerability Management \and Large Language Models \and SAST \and Security Automation}

\section{Introduction}

Software vulnerabilities like weaknesses in design, implementation, or configuration , enable attackers to compromise confidentiality, integrity, and availability, with consequences ranging from data breaches to supply-chain attacks. The presentation emphasized a growing gap between vulnerability discovery and remediation, supported by recent reports~\cite{action2025,cyentia2025}. Traditional Static Application Security Testing (SAST) tools struggle with false positives and false negatives and still rely heavily on expert judgment. SAP examined whether Large Language Models can help across the three stages of vulnerability management: detection, prioritization, and remediation.

\section{Vulnerability Detection with LLMs}

More than 300 studies have evaluated LLMs across many benchmark datasets with mixed outcomes~\cite{sheng2025}. In controlled, synthetic settings some LLMs outperform traditional SAST tools~\cite{tamberg2025}, but repository-level evaluations report high false-positive rates and inconsistent reasoning~\cite{gaucher2025}. LLMs can be non-deterministic and often struggle with complex or poorly documented code.

\begin{table}[ht]
\centering
\caption{Vulnerability remediation results (optimal temperature, top-p)}
\begin{tabular}{l l r r}
\hline
LLM & Prompting & Fix Success Rate & \# Vulnerable samples \\
\hline
GPT 4.1 & Zero shot & 85.9\% & 71 \\
Gemini 2.5 Flash & Zero shot & 77.3\% & 73 \\
Claude 4 Sonnet & Zero shot & 72.0\% & 75 \\
Gemini 2.5 Pro & Zero shot & 71.1\% & 73 \\
\hline
\end{tabular}
\label{tab:vuln-remediation}
\end{table}

\section{Prioritization and Remediation}

Research on automated prioritization remains limited. In SAP's collaboration with TU Braunschweig, the team constructed a ground-truth dataset of paired fixes focusing on common web languages to evaluate remediation quality. LLMs produced well-structured fixes in many cases,often preferring helper functions over one-line patches,but some human fixes were still incomplete or had design issues.

\section{Limitations and Future Directions}

LLMs are not yet reliable as standalone detection tools because of false positives and inconsistent outputs. Commercial auto-fix offerings exist and can accelerate remediation workflows, but expert review remains necessary to verify correctness and security. The likely future is hybrid, agentic systems that integrate LLMs with SAST/DAST/SCA tooling.This raises important questions about how to ensure deterministic detection and avoid introducing AI-generated vulnerabilities.

\section{Conclusions}

The presentation showed that LLMs offer powerful assistance for remediation and can produce high-quality fixes in many cases, but they do not replace human experts. Detection accuracy and consistent reasoning remain key obstacles, and prioritization methods are still early-stage.

Hybrid approaches that combine LLMs with traditional security tools and human oversight appear most practical. These AI-augmented workflows can help manage the widening gap between discovery and remediation, provided deployments include verification steps and appropriate safeguards.

\begin{thebibliography}{9}
\bibitem{action2025} Action1: Software Vulnerability Ratings Report 2025
\bibitem{cyentia2025} Cyentia: Why Your MTTR is Probably Bogus  
\bibitem{sheng2025} Sheng et al.: LLMs in Software Security. ACM Comput. Surv. (2025)
\bibitem{tamberg2025} Tamberg et al.: Harnessing LLMs for Vulnerability Detection. IEEE Access (2025)
\bibitem{gaucher2025} Gaucher et al.: Finding Vulnerabilities in Modern Web Apps. Semgrep (2025)
\end{thebibliography}

\end{document}
